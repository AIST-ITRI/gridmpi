<!-- -*-Mode: Fundamental;-*- -->
<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html><head>
<meta http-equiv="Content-Type" content="text/html;charset=iso-8859-1">
<title>Internals</title>
<link href="ref.css" rel="stylesheet" type="text/css">
</head>
<body>

<!--
<div class="index">
<a class="index" href="index.html">Main&nbsp;Page</a>
| <a class="index" href="modules.html">Modules</a>
| ......
| <a class="index" href="reference.html">Reference</a></div>
-->

<h1>Internals of GridMPI and YAMPI</h1>

<font size=-2><i>($Date: 2007/05/22 14:51:56 $)</i></font>

<p>This document describes the basic software organization needed for
developers to modify GridMPI and YAMPI.

<h3>Table of Contents:</h3>
<hr>
<ul>
<li><a href="#overview">Overview</a>
<!--<li><a href="#base">The MPI-API Layer</a>-->
<!--<li><a href="#req">The Request Layer</a>-->
<li><a href="#p2p">P2P Layer Interface</a>
<li><a href="#ext">Extension Mechanism (Library Loading)</a>
<li><a href="#impi">IMPI Issues</a>
<ul>
<li><a href="#impi.cid">CID Assignment under Threads</a>
</ul>
<!--<li><a href="#app.tcp">Appendix: TCP P2P</a>-->
<!--<li><a href="#app.pm">Appendix: SCore P2P</a>-->
<!--<li><a href="#app.shm">Appendix: MEM (SMP Shared Memory) P2P</a>-->
</ul>
<hr>

<!-- ================================================================ -->
<h2><a name="overview">Overview</a></h2>

<p>(in preparation)

<hr>

<h3>Software Layers and Source Files</h3>

<table border=1 rules=all cellpadding=3>
<tr><td align="center">
<i>(MPI API)</i><br>
fortran.c mpi1funcs.c mpi2funcs.c
<tr><td align="center">
<i>(API written in MPI)</i><br>
coll.c onesided.c fileio1.c fileio2.c fileio3.c
<tr><td align="center">
<i>(MPI Core Functions)</i><br>
communicator.c group.c keyval.c
operator.c topology.c errmsg.c misc.c
<tr><td align="center">
<i>(Basic Communication)</i><br>
sendrecv.c datatype.c packunpack.c
<tr><td align="center">
<i>(Request Mangement)</i><br>
request.c
<tr><td align="center">
<i>(Initialization)</i><br>
environment.c rpim.c process.c
<tr><td align="center">
<i>(Utilities)</i><br>
commops.c commdebugops.c prof.c ckpt.c
sockutil.c util-backtrace.c utility.c
</table>

<!-- ================================================================ -->
<h2><a name="p2p">P2P Layer Interface</a></h2>

<p>(The belows are the extracts from the source.  See the comments for
up-to-date descriptions).

<h3>Interfaces to P2P Layer</h3>

<p>Operations in the p2p-layer is invoked through a table in
<b>YamConHandle</b> (Connection Handler).

<dl>

<dt>int (*<b>topsend</b>)(struct YamConHandle*, YamReq*, int)

<dd>schedules a send of a YamReq.  Typically, it enqueues a YamReq in
the send queue.  The third argument of {topsend} indicates that it is
called from {_YampiPostSend}, in which case it is allowed to call
{_YampiPollP2P}, otherwise it is already called through it.  It is
called by any thread.

<dt>int (*<b>toprecv</b>)(struct YamConHandle*, YamReq*, YamReq*, int)

<dd>is called when a pulled YamReq and a posted YamReq are matched.
It may be null, if the p2p-layer does not need it.  It is called by
any thread.

<dt>int (*<b>netpush</b>)(struct YamConHandle*)

<dd>is regularly called to push messages from the send queue to the
network, when the select system call hits.  It may be null, if the
p2p-layer redefines the polling routine.  It is called by any thread.

<dt>int (*<b>netpull</b>)(struct YamConHandle*)

<dd>is also regularly called to pull messages from the network, when
the select system call hits.  It may be null, if the p2p-layer
redefines the polling routine.  It is called only through a monitor in
the polling routine.

<dt>int (*<b>netcancel</b>)(struct YamConHandle*, YamReq*)

<dd>is called by the request-layer to cancel YamReq.  It is called
only for send YamReqs.  Typically, it removes a YamReq from the send
queue.

<dt>int (*<b>netabort</b>)(struct YamConHandle*)

<dd>shutdowns the peer and makes it abort.

<dt>int (*<b>netclose</b>)(struct YamConHandle*);

<dd>is called at closure event or at finalization.

</dl>

<h3>Upcall Interfaces from P2P Layer</h3>

<p>Upcall interfaces from the p2p-layer are in <b>request.c</b>.

<dl>

<dt>YamReq *
<b>_YampiCheckRecv</b>(YamReq *req, void *data, int datasize)

<dd>Checks received header for matching recv.  It searches entries in
the expected queue, and replaces the request with the found one.  It
returns either a request passed to or the one in the expected queue.
It returns null when the request is PULL_RDYREQ.  MEMO: For transports
of TCP and Vendor-MPI, {data} is {req-&gt;yreq_anexdata}, and
{datasize} is {req-&gt;yreq_realsize}.

<dt>int
<b>_YampiFinishRecv</b>(YamReq *req)

<dd>Finishes a receive on receiving a whole message.  It is invoked by
the P2P-layer and request-layer.  Error condition is retuned (and
recorded in YamReq if not freed).  YamReq (not PULL) is normally
unaccessible after {_YampiFinishRecv}.  By convention, P2P-layer never
touch the YamReq after {_YampiFinishRecv}.  MEMO: Unpacking is
performed for a recv request (not for a pull request).

<dt>YamReqState
<b>_YampiFinishSend</b>(YamReq *req, int syncacked)

<dd>Finishes a send request on sending a whole message, or marks
{ssend_acked} flag.  State of send YamReq changes to SENT/DONE only
via this except in cancel cases.  YamReq is normally unaccessible
after {_YampiFinishSend}.  MEMO: Normally sender calls this, but
receiver can call this in case at receiving sync-ack or cancel-ack.
Both moves state from SENT to DONE and it is safe as not to interfere
with the sender.  NOTE: {syncacked} can be true, when the mode is not
SSEND in IMPI for long messages.

</dl>

<!--

<h3>方針</h3>

<ol>
<li>排他は GIANT。

<li>Request 層と P2P 層は普通は YamReq を排他的に
アクセスするので、排他は不要。
YamReq の DONE への transition だけ注意。
YamReq の DONE への transition には、_YampiFinishSend か
_YampiFinishRecv を使う。

<li>send は Request 層で排他せず、topsend、netpush まで行くので
P2P 層で排他。
(tcp.c で Request 層で排他すると明らかに遅かったのでそうした)。

<li>recv は Request 層で 1 つの thread に制限してから
P2P-poll (netpull) に行く (_yampiPollMonitor)。
注: mem2.c はそうなってない。

<li>netpull と postrecv との排他は _yampiP2PMonitor で行う。
netpull と postrecv は YamReq の横取り時 (overtake) に排他が必要。
注: 今は排他し過ぎ (YamReq 毎の排他の方がいいかも)。

<li>排他コードのほとんどは Request 層にある。
排他は、_yampiP2PMonitor と _yampiPollMonitor と _yampiPollMutex で
排他されている。ええ加減な区別で整理されてない。

</ol>

<h3>補足</h3>

<ol>

<li>send の排他: P2P-send (netpush) の呼び出しは P2P 側で排他。
典型的な動作は、netpush はキューにあるものは全て送る。
２番手以降の thread は topsend で単にキューに挿入するだけ。

<li>recv の排他: P2P-poll 呼び出しは 1 thread に制限。
どうせ select/poll するので Request 層で排他している。
２番手以降の thread は、wait するかどうかを見て
必要なら condvar で待つ (_yampiPollMonitor)。

<li>P2P 側の netpull と Request 中の postrecv は双方で排他。
YamReq の途中の横取り (overtake: unexpected を netpull してる途中で
postrecv が来たとき、unexpected を postrecv の YamReq で置き換える)
は _yampiP2PMonitor で排他。
注: system call が入るので mutex じゃなく monitor にしてある。

</ol>

<pre class="code">
MUTEX_LOCK(&mutex);
MUTEX_UNLOCK(&mutex);
MONITOR_ENTER(&monitor);
MONITRO_LEAVE(&monitor);
SINGLE_ENTER(&mutex);
SINGLE_LEAVE(&mutex);
</pre class="code">

-->

<h3>Thread Mutexing</h3>

<p>Thread mutexing is giant.  Normally the request-layer and the
p2p-layer access requests (YamReq) exclusively, and there is not
needed to mutex each other.  Only the DONE-transition needs mutexing,
and they are performed in {_YampiFinishSend} and {_YampiFinishRecv} in
normal operation.

<h3>Exclusion Monitors</h3>

<p>There are two kinds of monitors.  {_yampiPollMonitor} restricts
threads to one to enter the p2p-poll routine (which does select/poll
system calls).  {_yampiP2PMonitor} protects recv YamReqs between pull
in the p2p-layer and takeover in request-layer.

<p>The p2p-poll routine is mutexed by the request-layer and only one
thread can enter it.  But, p2p-send (NetPush) must be mutexed by
itself.  Normally, the first-entered p2p-send handles all requests,
and later sends immediately return.

<p>{_yampiPollMonitor} also tracks the state of the p2p-poll routine
which may enter sleep state in select/poll.  the p2p-layer should call
{_YampiPollSleepIn} and {_YampiPollSleepOut} around select/poll.

<h3>P2P Layer Interface for Exclusion</h3>

<p>(The belows are the extracts from the source.  See the comments for
up-to-date descriptions).

<dl>

<dt>int
<b>_YampiPollSleepIn</b>(void)

<dd>Tells request-layer poll goes to sleep.  It returns 1 if sleeping
is allowed.  It should call {_YampiPollSleepOut} when
{_YampiPollSleepIn} has been called.

<dt>void
<b>_YampiPollSleepOut</b>(void)

<dd>Tells request-layer poll goes out of sleep or never goes to sleep.
It must be called when {_YampiPollSleepIn} have been called.  It is
allowed not to call both of them.

<dt>void (*<b>_yampiP2PPollWake</b>)(void)

<dd>Wakes up a polling thread.  It should be able to wake up a thread
even if it is not in the sleep state yet.

</dl>

<hr>

<!-- ================================================================ -->
<h2><a name="ext">Extension Mechanism (Library Loading)</a></h2>

<p>GridMPI/YAMPI provides dynamic loading of library modules.

<hr>

<!-- ================================================================ -->
<h2><a name="">IMPI Issues</a></h2>

<h3><a name="impi.cid">CID Assignment under Threads</a></h3>

<p>The IMPI-specified CID (Communicator ID) assignment fails in races
under multi-thread environment.

<p>Two ALLREDUCEs are used in the algorithm.  One reduces CID value.
The other checks interference for other communicators.  Lower CID of
the communicator has precedence.  This precedence avoids locking
indefinitely.  Note that our algorithm assumes mutexing within a
communicator.  No concurrent operations on the same communicator for
dup/create/etc.

<hr>

<!-- ================================================================ -->
<h2><a name="">Appendix</a></h2>

<hr>

<!--
<table id="tbl">
<thead><tr>
<th>media</th><th>a1</th><th>a2</th></tr></thead>
<tbody><tr><th>Ultimate</th><td>b1</th><td>b2</th>
</tbody>
</table>
-->

</body>
</html>
